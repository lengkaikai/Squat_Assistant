{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apex_df = pd.read_csv('data/apex.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision trees good at overfitting small data points\n",
    "# ONE SHOT LEARNING- learn a differentiator rather than a predictor.  \n",
    "# maximize the difference between good score and bad score\n",
    "# transfer learning\n",
    "# combination of both\n",
    "# metrics, true positive, true negative, sensitivy, specificity, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Important features to look at for 'good' squats:\n",
    "1) angle at hip\n",
    "2) difference in x-coordinates of hip and ankle\n",
    "3) difference in y-coordinates of hip and knee\n",
    "'''\n",
    "\n",
    "features = apex_df.copy()\n",
    "features.head()\n",
    "features['xcoord_lhip_ank'] = features['leftHip_x'] - features['leftAnkle_x']\n",
    "features['ycoord_lhip_knee'] = features['leftHip_y'] - features['leftKnee_y']\n",
    "features['left_hip_angle'] = np.arctan(features['ycoord_lhip_knee']/features['xcoord_lhip_ank'])\n",
    "features['left_hip_angle']\n",
    "\n",
    "features['xcoord_rhip_ank'] = features['rightHip_x'] - features['rightAnkle_x']\n",
    "features['ycoord_rhip_knee'] = features['rightHip_y'] - features['rightKnee_y']\n",
    "features['right_hip_angle'] = np.arctan(features['ycoord_rhip_knee']/features['xcoord_rhip_ank'])\n",
    "features['right_hip_angle']\n",
    "\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A decision tree is built on an entire dataset, using all the features/variables of interest.\n",
    "Decision Tree Classifiers tend to overfit the small data points.\n",
    "'''\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "y = features['good']\n",
    "X = features.drop(['good'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "score = clf.score(X_test, y_test)\n",
    "print('Test Accuracy: ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Random Forest Classifiers choose randomly selects observations/rows\n",
    "and specific features/variables to build multiple decision trees from and then averages the results.\n",
    "'''\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "y = features['good']\n",
    "X = features.drop(['good'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "clf_rf = RandomForestClassifier()\n",
    "clf_rf = clf_rf.fit(X_train,y_train)\n",
    "y_pred_rf = clf_rf.predict(X_test)\n",
    "score_rf = clf_rf.score(X_test, y_test)\n",
    "print('Test Accuracy: ', score_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Logistic Regression conducts an analysis of the data when it is binary. \n",
    "In this case, it predicts the probability of getting a 'good' squat (1).\n",
    "'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "y = features['good']\n",
    "X = features.drop(['good'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "clf_log = LogisticRegression()\n",
    "clf_log = clf_log.fit(X_train,y_train)\n",
    "y_pred_log = clf_log.predict(X_test)\n",
    "score_log = clf_log.score(X_test, y_test)\n",
    "print('Test Accuracy: ', score_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Installation of pip, tensorflow, keras:\n",
    "run this in terminal to install pip:  curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n",
    "run this in terminal to install tensorflow: pip install --upgrade tensorflow\n",
    "run this in terminal to install keras: pip install keras\n",
    "'''\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = features['good']\n",
    "x = features.drop(['good'], axis=1)\n",
    "#pd.get_dummies(y).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42,shuffle=True)\n",
    "\n",
    "# Core data structure in Keras is a model\n",
    "# The model is an object in which we organize layers\n",
    "\n",
    "model_k = Sequential() # instantiate empty Sequential model\n",
    "\n",
    "\n",
    "# model contruction (architecture build computational graph)\n",
    "\n",
    "\n",
    "model_k.add( Dense(units=64, input_dim = 25, activation='relu'))\n",
    "\n",
    "model_k.add(Dense(32, activation=tf.nn.relu))\n",
    "\n",
    "#model_k.add(Dense(16, activation=tf.nn.relu))\n",
    "\n",
    "model_k.add(Dense(4, activation='sigmoid'))\n",
    "\n",
    "model_k.add(Dense(units=1, activation='softmax') )\n",
    "\n",
    "\n",
    "# For a binary classification problem \n",
    "#def mean_pred(y_true, y_pred):\n",
    " #   return keras.backend.mean(y_pred) \n",
    "\n",
    "model_k.compile(optimizer= 'rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history = model_k.fit(X_train, y_train, epochs =10, batch_size= 10)\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "import pickle\n",
    "joblib.dump(model_k, './data/model.pkl')\n",
    "# Evaluate the model Accuracy on test set\n",
    "\n",
    "loss, accuracy = model_k.evaluate(X_test, y_test, batch_size=10)\n",
    "#print('Test loss:', test_scores[0])\n",
    "print('Test accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "k nearest neighbors model works by taking a data point and looking at the ‘k’ closest labeled data points. \n",
    "The data point is then assigned the label of the majority of the ‘k’ closest points. In this case, we want\n",
    "to take the features and label it as good or bad (1 or 0).\n",
    "K-folds cross validation estimates the skill of the k nearest neighbors model. In this case, \n",
    "the data-set is split into k (5) groups and one group is used as the test set and the rest\n",
    "are used as the training set.\n",
    "'''\n",
    "\n",
    "feat = features.copy()\n",
    "#feat = feat.drop(['good'], axis=1)\n",
    "feat_new = feat[['xcoord_lhip_ank','ycoord_lhip_knee','left_hip_angle','xcoord_rhip_ank','ycoord_rhip_knee','right_hip_angle', 'good']]\n",
    "y = feat_new['good']\n",
    "x = feat_new.drop(['good'], axis=1)\n",
    "#Cluster the data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1, stratify=y)\n",
    "\n",
    "# Create KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "# Fit the classifier to the data\n",
    "knn.fit(X_train,y_train)\n",
    "knn.predict(X_test)[0:5]\n",
    "knn_score = knn.score(X_test, y_test)\n",
    "\n",
    "#create a new KNN model\n",
    "knn_cv = KNeighborsClassifier(n_neighbors=3)\n",
    "#train model with cv of 5 \n",
    "cv_scores = cross_val_score(knn_cv, x, y, cv=5)\n",
    "#print each cv score (accuracy) and average them\n",
    "print('Accuracy:', knn_score)\n",
    "print('Cross Validation Mean:{}'.format(np.mean(cv_scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feat.shape\n",
    "#kmeans = KMeans(n_clusters=2).fit(feat_new)\n",
    "#centroids = kmeans.cluster_centers_\n",
    "#print(centroids)\n",
    "\n",
    "\n",
    "#kmeans = KMeans(n_clusters=2, random_state=42).fit(feat_std)\n",
    "#labels = kmeans.labels_\n",
    "\n",
    "#Glue back to originaal data\n",
    "#feat['clusters'] = labels\n",
    "\n",
    "#Add the column into our list\n",
    "#feat(['clusters'])\n",
    "\n",
    "#Lets analyze the clusters\n",
    "#feat['good'].groupby(['clusters']).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
