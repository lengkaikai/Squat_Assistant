{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "FILE_PATH = \"./data/training/good/\"\n",
    "FILE_NAME = \"log1.json\"\n",
    "# dataDictList is a list of dicts\n",
    "with open(FILE_PATH+FILE_NAME, 'r') as f:\n",
    "    dataDictList = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update apex.csv\n",
    "MUST RUN ALL CELLS IN HELPER FUNCTIONS BEFORE FUNCTIONAL\n",
    "\n",
    "Running this cell will update the \"apex.csv\" with information based in the \"training\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting findAllApex\n",
      "--------------------\n",
      "Good squats: 1\n",
      "Bad squats: 1\n",
      "--------------------\n",
      "File path: data/training/good/log1.json\n",
      "116 entries\n",
      "Entry with apex = 37\n",
      "--------------------\n",
      "File path: data/training/bad/log2.json\n",
      "116 entries\n",
      "Entry with apex = 37\n",
      "--------------------\n",
      "apex.csv updated\n",
      "Finish findAllApex\n",
      "Found apexes of all 2 squats\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nose_x</th>\n",
       "      <th>nose_y</th>\n",
       "      <th>leftShoulder_x</th>\n",
       "      <th>leftShoulder_y</th>\n",
       "      <th>rightShoulder_x</th>\n",
       "      <th>rightShoulder_y</th>\n",
       "      <th>leftHip_x</th>\n",
       "      <th>leftHip_y</th>\n",
       "      <th>rightHip_x</th>\n",
       "      <th>rightHip_y</th>\n",
       "      <th>leftKnee_x</th>\n",
       "      <th>leftKnee_y</th>\n",
       "      <th>rightKnee_x</th>\n",
       "      <th>rightKnee_y</th>\n",
       "      <th>leftAnkle_x</th>\n",
       "      <th>leftAnkle_y</th>\n",
       "      <th>rightAnkle_x</th>\n",
       "      <th>rightAnkle_y</th>\n",
       "      <th>good</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entry</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.186076</td>\n",
       "      <td>0.049323</td>\n",
       "      <td>0.138497</td>\n",
       "      <td>0.136038</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.108029</td>\n",
       "      <td>0.250127</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>0.385698</td>\n",
       "      <td>0.160566</td>\n",
       "      <td>0.391882</td>\n",
       "      <td>0.17095</td>\n",
       "      <td>0.19583</td>\n",
       "      <td>0.060988</td>\n",
       "      <td>0.403104</td>\n",
       "      <td>0.153628</td>\n",
       "      <td>0.409191</td>\n",
       "      <td>0.149827</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.186076</td>\n",
       "      <td>0.049323</td>\n",
       "      <td>0.138497</td>\n",
       "      <td>0.136038</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.108029</td>\n",
       "      <td>0.250127</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>0.385698</td>\n",
       "      <td>0.160566</td>\n",
       "      <td>0.391882</td>\n",
       "      <td>0.17095</td>\n",
       "      <td>0.19583</td>\n",
       "      <td>0.060988</td>\n",
       "      <td>0.403104</td>\n",
       "      <td>0.153628</td>\n",
       "      <td>0.409191</td>\n",
       "      <td>0.149827</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         nose_x    nose_y  leftShoulder_x  leftShoulder_y  rightShoulder_x  \\\n",
       "entry                                                                        \n",
       "0      0.186076  0.049323        0.138497        0.136038            0.275   \n",
       "1      0.186076  0.049323        0.138497        0.136038            0.275   \n",
       "\n",
       "       rightShoulder_y  leftHip_x  leftHip_y  rightHip_x  rightHip_y  \\\n",
       "entry                                                                  \n",
       "0             0.108029   0.250127   0.002908    0.385698    0.160566   \n",
       "1             0.108029   0.250127   0.002908    0.385698    0.160566   \n",
       "\n",
       "       leftKnee_x  leftKnee_y  rightKnee_x  rightKnee_y  leftAnkle_x  \\\n",
       "entry                                                                  \n",
       "0        0.391882     0.17095      0.19583     0.060988     0.403104   \n",
       "1        0.391882     0.17095      0.19583     0.060988     0.403104   \n",
       "\n",
       "       leftAnkle_y  rightAnkle_x  rightAnkle_y  good  \n",
       "entry                                                 \n",
       "0         0.153628      0.409191      0.149827     1  \n",
       "1         0.153628      0.409191      0.149827     0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates \n",
    "apex_df = findAllApex('data/training', update = True)\n",
    "apex_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n",
    "\n",
    "Contains 4 functions\n",
    "##### genList - reads json file into dataframe\n",
    "##### scale - normalizes dataframe\n",
    "##### findApex - finds apex coordinate of dataframe\n",
    "##### findAllApex - returns dataframe with all apexes\n",
    "\n",
    "## Global Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARTS =  {\"nose\" : 0, \n",
    "  \"leftEye\" : 1, \n",
    "  \"rightEye\" : 2, \n",
    "  \"leftEar\" : 3, \n",
    "  \"rightEar\" : 4, \n",
    "  \"leftShoulder\" : 5, \n",
    "  \"rightShoulder\" : 6, \n",
    "  \"leftElbow\" : 7, \n",
    "  \"rightElbow\" : 8, \n",
    "  \"leftWrist\" : 9, \n",
    "  \"rightWrist\" : 10, \n",
    "  \"leftHip\" : 11, \n",
    "  \"rightHip\" : 12, \n",
    "  \"leftKnee\" : 13, \n",
    "  \"rightKnee\" : 14, \n",
    "  \"leftAnkle\" : 15, \n",
    "  \"rightAnkle\" : 16}\n",
    "\n",
    "requiredParts = [\"nose\", \n",
    "#   \"leftEye\", \n",
    "#   \"rightEye\", \n",
    "#   \"leftEar\", \n",
    "#   \"rightEar\", \n",
    "  \"leftShoulder\", \n",
    "  \"rightShoulder\", \n",
    "#   \"leftElbow\", \n",
    "#   \"rightElbow\", \n",
    "#   \"leftWrist\", \n",
    "#   \"rightWrist\", \n",
    "  \"leftHip\", \n",
    "  \"rightHip\", \n",
    "  \"leftKnee\", \n",
    "  \"rightKnee\", \n",
    "  \"leftAnkle\", \n",
    "  \"rightAnkle\"\n",
    "]\n",
    "\n",
    "IMAGE_X_SIZE = 600\n",
    "IMAGE_Y_SIZE = 450"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read json file\n",
    "genList reads a json file and creates an table of the X and Y coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 entries\n"
     ]
    }
   ],
   "source": [
    "def genList(dataDictList, requiredParts, startIndex, stopIndex):\n",
    "    '''\n",
    "    @args\n",
    "    dataDictList - json load\n",
    "    requiredParts - [\"nose\", etc.]\n",
    "    startIndex - relative timestamp to start. 0\n",
    "    stopIndex - relative timestamp to stop. len(dataDictList)\n",
    "    @returns\n",
    "    [#, x], [#, y]\n",
    "    '''\n",
    "    dataListX = None\n",
    "    dataListY = None\n",
    "    for _frame in range(startIndex, stopIndex):\n",
    "        if dataListX is None:\n",
    "            dataListX = [[dataDictList[_frame]['keypoints'][PARTS[X]]['position']['x'] for X in requiredParts]]\n",
    "            dataListY = [[dataDictList[_frame]['keypoints'][PARTS[X]]['position']['y'] for X in requiredParts]]\n",
    "        else:\n",
    "            dataListX = dataListX + [[dataDictList[_frame]['keypoints'][PARTS[_part]]['position']['x'] for _part in requiredParts]]\n",
    "            dataListY = dataListY + [[dataDictList[_frame]['keypoints'][PARTS[_part]]['position']['y'] for _part in requiredParts]]\n",
    "    \n",
    "    dataListX = np.array(dataListX) # [[x]]\n",
    "    dataListY = np.array(dataListY) # [[y]]\n",
    "    newDataListX = np.reshape(dataListX, (-1,len(requiredParts))) \n",
    "    newDataListY = np.reshape(dataListY, (-1,len(requiredParts))) #[#instance, (y) for each keypoint]\n",
    "    print(str(len(newDataListX)) + \" entries\")\n",
    "    return newDataListX, newDataListY\n",
    "\n",
    "\n",
    "newDataListX, newDataListY = genList(dataDictList, requiredParts, 0, len(dataDictList))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "Normalizes coordinates for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " This has 2 parts-\n",
    " Resize, by identifying and scaling as bounding box, and then (Min-Max) Normalize\n",
    " Note: The broadcasting here is element-wise. \n",
    " Sources:\n",
    " [1] https://medium.com/tensorflow/move-mirror-an-ai-experiment-with-pose-estimation-in-the-browser-using-tensorflow-js-2f7b769f9b23\n",
    " [2] https://raw.githubusercontent.com/paulvollmer/posenet-keypoints-normalization/master/src/index.js\n",
    " \n",
    "\n",
    "''' \n",
    "\n",
    "def scale(newDataListX, newDataListY):\n",
    "    '''\n",
    "    Assumes dataList of form [#instance, [(x,y) for each keypoint]]\n",
    "    Possible optim: bounding box wont change much across frames\n",
    "    '''\n",
    "    # Bounding Box\n",
    "    maxX = np.max(newDataListX, axis=1)\n",
    "    minX = np.min(newDataListX, axis=1)\n",
    "    maxY = np.max(newDataListY, axis=1)\n",
    "    minY = np.min(newDataListY, axis=1)\n",
    "    assert(len(minY)==len(newDataListX))\n",
    "    l2Data = np.concatenate((newDataListX, newDataListY), axis=1)\n",
    "    # Reset to Origin and Scale\n",
    "    for _data in range(0, len(newDataListX)):\n",
    "        l2Data[_data] = l2Data[_data] / np.linalg.norm(l2Data[_data]) # L2 norm if the need be\n",
    "    return l2Data[:,:newDataListX.shape[-1]], l2Data[:,newDataListY.shape[-1]:]\n",
    "\n",
    "scaledDataX, scaledDataY = scale(newDataListX, newDataListY)\n",
    "\n",
    "\n",
    "x_key=pd.DataFrame(scaledDataX)\n",
    "y_key=pd.DataFrame(scaledDataY)\n",
    "x_key.columns=requiredParts\n",
    "y_key.columns=requiredParts\n",
    "keydoc=FILE_NAME[:-5]\n",
    "x_key.to_csv(FILE_PATH+keydoc+\"_x.csv\")\n",
    "y_key.to_csv(FILE_PATH+keydoc+\"_y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Apex\n",
    "Finds the normalized apex for a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findApex(xTbl, yTbl):\n",
    "    minColumnIndex = yTbl['leftHip'].idxmin()\n",
    "    print(\"Entry with apex = \" + str(minColumnIndex))\n",
    "    xTblApex = xTbl.iloc[minColumnIndex,:]\n",
    "    yTblApex = yTbl.iloc[minColumnIndex,:]\n",
    "    apex = []\n",
    "    for i in range(len(xTblApex)):\n",
    "        xTblVal = xTblApex[i]\n",
    "        yTblVal = yTblApex[i]\n",
    "        apex.append(xTblVal)\n",
    "        apex.append(yTblVal)\n",
    "    return apex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find All Apexes\n",
    "Runs findApex on every json file in training, creating dataframe of all apexes classified based off the folder they're in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAllApex(training_path, update):\n",
    "    print(\"Starting findAllApex\")\n",
    "    print(\"--------------------\")\n",
    "    # Creats index names for final table, each part and each coordinate having separate columns\n",
    "    columnIndices = []\n",
    "    for index in requiredParts:\n",
    "        columnIndices.append(index + \"_x\")\n",
    "        columnIndices.append(index + \"_y\")\n",
    "    columnIndices.append(\"good\")\n",
    "        \n",
    "    #Creates list of paths for json files\n",
    "    goodJson = []\n",
    "    for file in os.listdir(training_path + \"/good\"):\n",
    "        if file.endswith(\".json\"):\n",
    "            goodJson.append(os.path.join(training_path + \"/good\", file))\n",
    "    badJson = []\n",
    "    for file in os.listdir(training_path + \"/bad\"):\n",
    "        if file.endswith(\".json\"):\n",
    "            badJson.append(os.path.join(training_path + \"/bad\", file))\n",
    "    jsonList = [goodJson, badJson]\n",
    "    \n",
    "    apexes = []\n",
    "    type = 1\n",
    "    print(\"Good squats: \" + str(len(goodJson)))\n",
    "    print(\"Bad squats: \" + str(len(badJson)))\n",
    "    print(\"--------------------\")\n",
    "    for jsonFolder in jsonList:\n",
    "        for path in jsonFolder:\n",
    "            print(\"File path: \" + path)\n",
    "            with open(path, 'r') as f:\n",
    "                dataDictList = json.load(f)\n",
    "            newDataListX, newDataListY = genList(dataDictList, requiredParts, 0, len(dataDictList))\n",
    "            scaledDataX, scaledDataY = scale(newDataListX, newDataListY)\n",
    "            x_key=pd.DataFrame(scaledDataX)\n",
    "            y_key=pd.DataFrame(scaledDataY)\n",
    "            x_key.columns=requiredParts\n",
    "            y_key.columns=requiredParts\n",
    "            apex_point = findApex(x_key, y_key)\n",
    "            apex_point.append(type)\n",
    "            apexes.append(apex_point)\n",
    "            print(\"--------------------\")\n",
    "        type = 0\n",
    "    apex_df = pd.DataFrame(apexes, columns = columnIndices)\n",
    "    apex_df.index.name = 'entry'\n",
    "    if update == True:\n",
    "        apex_df.to_csv('data/apex.csv')\n",
    "        print(\"apex.csv updated\")\n",
    "    print(\"Finish findAllApex\")\n",
    "    print(\"Found apexes of all \"+ str(len(apex_df)) + \" squats\")\n",
    "    return apex_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose if you want to plot X or Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "fig=plt.figure(figsize=(10, 15), dpi= 80, facecolor='w', edgecolor='k')\n",
    "num_graphs = 5\n",
    "index = 0\n",
    "for sub in range(0, num_graphs, 1):\n",
    "    plt.subplot(5, 3, 3*sub+1)\n",
    "    plt.plot(newDataListX[:,index], 'ko-')\n",
    "    plt.title(requiredParts[index])\n",
    "    plt.ylabel('Actual')\n",
    "\n",
    "    plt.subplot(5, 3, 3*sub+2)\n",
    "    plt.plot(scaledDataX[:,index],  'r.-')\n",
    "    plt.title(requiredParts[index])\n",
    "    plt.ylabel('Scaled X')\n",
    "    \n",
    "    plt.subplot(5, 3, 3*sub+3)\n",
    "    plt.plot(scaledDataY[:,index],  'r.-')\n",
    "    plt.title(requiredParts[index])\n",
    "    plt.ylabel('Scaled Y')\n",
    "    index = index + 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=5\n",
    "fig=plt.figure(figsize=(10, 15), dpi= 80, facecolor='w', edgecolor='k')\n",
    "for sub in range(0, 4, 1):\n",
    "    plt.subplot(4, 3, 3*sub+1)\n",
    "    plt.plot(newDataListX[:,index], 'ko-')\n",
    "    plt.title(requiredParts[index])\n",
    "    plt.ylabel('Actual')\n",
    "    plt.subplot(4, 3, 3*sub+2)\n",
    "    plt.plot(scaledDataX[:,index],  'r.-')\n",
    "    plt.title(requiredParts[index])\n",
    "    plt.ylabel('ScaledX')\n",
    "    plt.subplot(4, 3, 3*sub+3)\n",
    "    plt.plot(scaledDataY[:,index],  'r.-')\n",
    "    plt.title(requiredParts[index])\n",
    "    plt.ylabel('ScaledY')\n",
    "    index = index+1\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig=plt.figure(figsize=(10, 15), dpi= 80, facecolor='w', edgecolor='k')\n",
    "# for sub in range(0, 4, 1):\n",
    "#     plt.subplot(5, 3, (3*sub+1))\n",
    "#     plt.plot(newDataListX[:,index], 'ko-')\n",
    "#     plt.title(requiredParts[index])\n",
    "#     plt.ylabel('Actual')\n",
    "#     plt.subplot(5, 3, (3*sub+2))\n",
    "#     plt.plot(scaledDataX[:,index],  'r.-')\n",
    "#     plt.title(requiredParts[index])\n",
    "#     plt.ylabel('ScaledX')\n",
    "#     plt.subplot(5, 3, (3*sub+3))\n",
    "#     plt.plot(scaledDataY[:,index],  'r.-')\n",
    "#     plt.title(requiredParts[index])\n",
    "#     plt.ylabel('ScaledY')\n",
    "#     index = index+1\n",
    "    \n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(5, 5), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.plot(x_key);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
